{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# CSV読み込み・データ整理\n",
    "df = pd.read_csv('/content/drive/MyDrive/spam.csv', encoding='latin-1')\n",
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "df.rename(columns={\"v1\":\"label\", \"v2\":\"text\"}, inplace=True)\n",
    "df.head()\n",
    "X = pd.DataFrame(df[\"text\"])\n",
    "y = pd.DataFrame(df[\"label\"])\n",
    "#7：3でデータセットを分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "# 単語の出現回数取得\n",
    "vectorizer = CountVectorizer(min_df=5)\n",
    "# vectorizerをもとにエンコード\n",
    "X_train_vec = vectorizer.fit_transform(X_train[\"text\"])\n",
    "X_test_vec = vectorizer.transform(X_test[\"text\"])\n",
    "y_train = y_train[\"label\"]\n",
    "y_test = y_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.classes= [\"ham\",\"spam\"] #各カテゴリ\n",
    "        self.length = 1416 #全学習データの中に出現する、重複を除いた全語句の数(語彙)→N_all\n",
    "        self.prob_priors = [0.0, 0.0] #全学習データのうち、ham/spamに属するデータの割合→r_cat\n",
    "        self.word_likelihoods = np.zeros((2, self.length)) #各カテゴリにおいて、ある語句が起こる確率→P(cat)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        for i, c in enumerate(self.classes):\n",
    "            self.prob_priors[i] = np.mean(y == c)\n",
    "            class_index = [k for k, j in enumerate(y) if j == c]\n",
    "            X_c = X[class_index]\n",
    "            N_w = np.squeeze(np.array(np.sum(X_c, axis=0)))#各カテゴリに属する、ある語句の数→N_w\n",
    "            N_cat = np.sum(N_w)#各カテゴリに属する、全ての語句の数→N_cat\n",
    "            for idx, k in enumerate(N_w):\n",
    "                self.word_likelihoods[i][idx] = (k + 1)/(N_cat + self.length)#数式の右項の第二項\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = [] #最終的な予測カテゴリを格納する\n",
    "        classes = [0,1]\n",
    "        p_cat=[0.0, 0.0] #各カテゴリの尤度\n",
    "        X = (X > 0).astype(int).toarray()#Xを語彙リストに基づいて0/1のリストに変換\n",
    "        for x in X : #xにはバイナリデータが入っており、各単語が出現したか否かがわかる\n",
    "            for c in classes:\n",
    "                p_cat[c] = np.log(self.prob_priors[c])\n",
    "                for idx, i in enumerate(x):\n",
    "                    if i == 1:\n",
    "                        p_cat[c]+= np.log(self.word_likelihoods[c][idx])\n",
    "            #カテゴリ分類\n",
    "            if p_cat[0] > p_cat[1]:\n",
    "                prediction.append(\"ham\")\n",
    "            else :\n",
    "                prediction.append(\"spam\")\n",
    "        return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#精度検証\n",
    "def acc(pred, ans):\n",
    "    correct = 0\n",
    "    for idx, k in enumerate(ans):\n",
    "        if k == pred[idx]:\n",
    "            correct = correct + 1\n",
    "    print(correct / len(pred)) #予測カテゴリが真のカテゴリと一致した確率\n",
    "#実装\n",
    "nb = NaiveBayesClassifier()\n",
    "#学習\n",
    "n = nb.fit(X_train_vec, y_train)\n",
    "#予測\n",
    "y_pred = nb.predict(X_test_vec)\n",
    "#精度\n",
    "acc(y_pred, y_test) #0.9802631578947368\n",
    "print(y_pred) #確認用\n",
    "print(y_test.tolist()) #確認用"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
